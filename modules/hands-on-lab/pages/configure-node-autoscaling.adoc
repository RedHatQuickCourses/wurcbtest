#  Configure node autoscaling

= Configure Node Autoscaling

This section details how to configure node autoscaling in Azure Red Hat OpenShift (ARO) clusters, a critical capability for optimizing resource utilization, managing costs, and ensuring application performance under varying loads.

== Node Autoscaling in Azure Red Hat OpenShift

Node autoscaling in Azure Red Hat OpenShift allows your cluster to automatically adjust the number of worker nodes based on the pending resource requests of your workloads. This dynamic scaling ensures that your applications have sufficient resources when demand increases and reduces costs by scaling down nodes when demand decreases.

OpenShift leverages the Kubernetes Cluster Autoscaler, working in conjunction with OpenShift's Machine API, to achieve this functionality.

=== How Node Autoscaling Works

The core components involved in node autoscaling in ARO are:

*   **Cluster Autoscaler**: This component monitors for unschedulable pods (pods that cannot be scheduled due to insufficient resources on existing nodes). When it detects such pods, it communicates with the Machine API to request an increase in the number of nodes. It also identifies underutilized nodes and requests their removal when appropriate, ensuring that scaling down does not disrupt running applications (respecting Pod Disruption Budgets, PDBs).
*   **MachineSet**: A MachineSet is an OpenShift API object that defines a group of machines (VMs) with identical configurations. It acts similarly to a ReplicaSet for pods, but for infrastructure machines. MachineSets are responsible for creating, configuring, and managing the lifecycle of your worker nodes in Azure. A typical ARO cluster comes with default worker MachineSets.
*   **MachineAutoscaler**: This OpenShift API object links a specific MachineSet to the Cluster Autoscaler. It defines the minimum and maximum number of replicas (nodes) for that particular MachineSet. The Cluster Autoscaler then uses these boundaries to instruct the MachineAutoscaler to scale the associated MachineSet up or down.

image::cluster-autoscaler-flow.png[Cluster Autoscaler Flow, width=800, align=center]
_Figure: The Cluster Autoscaler monitors pending pods and interacts with MachineAutoscalers to adjust MachineSets, which in turn scale Azure VMs._

When you configure node autoscaling, you essentially define a `MachineAutoscaler` resource that targets a specific `MachineSet`. The `MachineAutoscaler` specifies the `minReplicas` and `maxReplicas` for that `MachineSet`. The Cluster Autoscaler then observes the cluster's resource needs and, if necessary, scales the `MachineSet` within these defined boundaries by creating or deleting Azure VMs.

=== Benefits of Node Autoscaling

*   **Cost Optimization**: Automatically scales down nodes during periods of low demand, reducing cloud infrastructure costs.
*   **Improved Performance and Availability**: Ensures applications always have enough resources, preventing performance degradation and improving reliability during peak loads.
*   **Resource Efficiency**: Prevents over-provisioning of resources by dynamically matching compute capacity to workload requirements.
*   **Operational Simplicity**: Automates the manual process of adding or removing nodes, freeing up administrator time.

=== Considerations for Node Autoscaling

*   **Resource Requests and Limits**: For accurate autoscaling, it is crucial that your application pods have appropriate `requests` and `limits` defined for CPU and memory. The Cluster Autoscaler relies on these values to make scaling decisions.
*   **Pod Disruption Budgets (PDBs)**: To prevent service disruptions during scale-down events, configure PDBs for critical applications. The Cluster Autoscaler respects PDBs when removing nodes.
*   **Node Affinity/Selectors**: If you have specific workloads that need to run on certain types of nodes (e.g., nodes with GPUs, or spot instances as mentioned in the context), ensure your pods use `nodeSelectors` or `nodeAffinity` rules to target those nodes. This also applies when scaling heterogeneous node groups.
*   **Azure Quotas**: Ensure your Azure subscription has sufficient quota for the VM sizes and regions your cluster uses, especially when planning for significant scale-up events. The context explicitly mentions setting quota for Spot instances slightly higher.

== Hands-on Activity: Configuring Node Autoscaling for Spot Instances

In this lab, you will configure node autoscaling for a dedicated `MachineSet` utilizing Azure Spot Virtual Machines. Spot VMs are a cost-effective option for interruptible workloads, leveraging unused Azure capacity. The Cluster Autoscaler can manage these nodes efficiently, scaling them up and down as needed.

*Estimated Time:* 30-45 minutes

=== Prerequisites

*   An Azure Red Hat OpenShift (ARO) cluster.
*   The `oc` CLI tool configured and logged in to your ARO cluster with cluster-admin privileges.
*   Sufficient Azure quota for the VM size you intend to use for Spot instances (e.g., `Standard_E4s_v5`).
*   An understanding of creating a dedicated machine set (covered in the 'Creating dedicated machine sets' objective). If you haven't done so, the first step of this lab will guide you through creating one for Spot instances.

=== Lab Steps

.Login to your ARO Cluster
Open your terminal and log in to your ARO cluster using the `oc` CLI:

[source,bash,subs="attributes+"]
----
oc login --token=<your_token> --server=<your_api_server>
----

.Identify Existing Worker MachineSets
First, let's see the existing worker MachineSets in your cluster. This helps us understand the naming conventions and provides a template for our new MachineSet.

[source,bash]
----
oc get machinesets -n openshift-machine-api
----

You should see output similar to this:
[source,text]
----
NAME                                     DESIRED   CURRENT   READY   AVAILABLE   AGE
aro-cluster-xxxx-worker-eastus1   3         3         3       3           3d1h
----
Note the name of one of your existing worker MachineSets (e.g., `aro-cluster-xxxx-worker-eastus1`). We will use its configuration as a base.

.Create a New MachineSet for Azure Spot Instances
We will create a new MachineSet specifically for Spot VMs. This allows us to separate these cost-effective, interruptible nodes from your regular on-demand nodes.

a. *Export an existing MachineSet configuration:*
   Replace `<EXISTING_MACHINESET_NAME>` with the name you identified in the previous step.

   [source,bash]
   ----
   oc get machineset <EXISTING_MACHINESET_NAME> -n openshift-machine-api -o yaml > spot-machineset.yaml
   ----

b. *Edit the `spot-machineset.yaml` file:*
   Open `spot-machineset.yaml` in your preferred text editor. You need to make the following modifications:

   *   Change the `name` under `metadata` to something unique, e.g., `aro-cluster-xxxx-spot-worker-eastus1`.
   *   Remove the `uid`, `resourceVersion`, `creationTimestamp`, and `selfLink` fields from `metadata`.
   *   Change `spec.replicas` to `0`. We want the autoscaler to manage these nodes from scratch.
   *   Add a specific `label` to `spec.template.spec.metadata.labels`. This label will be used by our pods to target these spot nodes. For example:
       [source,yaml]
       ----
         spec:
           template:
             metadata:
               labels:
                 machine.openshift.io/cluster-api-cluster: aro-cluster-xxxx # Keep existing label
                 machine.openshift.io/cluster-api-machine-role: worker # Keep existing label
                 machine.openshift.io/cluster-api-machine-type: worker # Keep existing label
                 node-role.kubernetes.io/spot: "" # <1>
       ----
       <1> Add this custom label.
   *   Modify `spec.template.spec.providerSpec.value` to configure it for Spot VMs. Specifically, add `spotVmOptions` and adjust the `sku.name` if desired for a different VM size. For example:
       [source,yaml]
       ----
         providerSpec:
           value:
             image:
               offer: aro-rhcos
               publisher: redhat
               resourceGroup: aro-cluster-xxxx-rg
               sku: aro-rhcos # Keep existing
               version: latest
             internalLoadBalancer: ""
             kind: AzureMachineProviderSpec
             location: eastus
             networkResources:
               networkInterfaces:
               - loadBalancerBackendPool: ""
                 natRule: ""
                 privateIP: ""
                 publicIP: ""
                 securityGroup: aro-cluster-xxxx-nsg
                 subnet: aro-cluster-xxxx-worker-subnet
             osDisk:
               diskSizeGB: 128
               managedDisk:
                 storageAccountType: Premium_LRS
               osType: Linux
             publicIP: false
             resourceGroup: aro-cluster-xxxx-rg
             spotVmOptions: # <1>
               maxPrice: "-1" # <2>
             sshKeyPair: {}
             tags:
               cluster.k8s.io/cluster-api-cluster/aro-cluster-xxxx: owned
               redhat_openshift_machine: "true"
             userDataSecret:
               name: worker-user-data
             vmSize: Standard_E4s_v5 # <3>
             vnet: aro-cluster-xxxx-vnet
             zone: "1" # Keep or remove if you want Azure to pick
       ----
       <1> Add the `spotVmOptions` block.
       <2> `-1` indicates no maximum price, meaning the VM will not be evicted due to price increases, only capacity. You can specify a monetary value here if you wish.
       <3> Change to a suitable VM size for Spot (e.g., `Standard_E4s_v5` is often a good choice for smaller workloads).

c. *Apply the new MachineSet:*

   [source,bash]
   ----
   oc apply -f spot-machineset.yaml -n openshift-machine-api
   ----

d. *Verify the new MachineSet:*

   [source,bash]
   ----
   oc get machinesets -n openshift-machine-api
   ----
   You should see your new `spot-worker` MachineSet with `DESIRED` replicas as `0`.

.Create a MachineAutoscaler for the Spot MachineSet
Now, let's create a `MachineAutoscaler` that will manage the scaling of your new spot `MachineSet`.

a. *Create a `machineautoscaler.yaml` file* with the following content.
   Replace `aro-cluster-xxxx-spot-worker-eastus1` with the name of your newly created MachineSet.

   [source,yaml]
   ----
   apiVersion: autoscaling.openshift.io/v1beta1
   kind: MachineAutoscaler
   metadata:
     name: spot-worker-autoscaler
     namespace: openshift-machine-api
   spec:
     minReplicas: 0 # <1>
     maxReplicas: 3 # <2>
     scaleTargetRef:
       apiVersion: machine.openshift.io/v1beta1
       kind: MachineSet
       name: aro-cluster-xxxx-spot-worker-eastus1 # <3>
   ----
   <1> Minimum number of spot worker nodes to maintain. Set to 0 to save costs when not in use.
   <2> Maximum number of spot worker nodes the autoscaler can provision.
   <3> The name of your spot MachineSet created in the previous step.

b. *Apply the MachineAutoscaler:*

   [source,bash]
   ----
   oc apply -f machineautoscaler.yaml
   ----

c. *Verify the MachineAutoscaler status:*

   [source,bash]
   ----
   oc get machineautoscaler -n openshift-machine-api
   ----
   You should see your `spot-worker-autoscaler` listed.

.Test Node Autoscaling
Now, let's deploy an application that requires more resources than currently available on your non-spot nodes. We'll specifically target the new spot nodes using the label we added earlier.

a. *Create a new project for your test application:*

   [source,bash]
   ----
   oc new-project autoscaling-test
   ----

b. *Create a deployment for a demanding application* that targets your spot nodes.
   Create a file named `test-app-deployment.yaml` with the following content. This example uses a simple NGINX image but with a high replica count and a node selector to target your `spot` nodes.

   [source,yaml]
   ----
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     name: high-demand-app
     labels:
       app: high-demand-app
   spec:
     replicas: 15 # <1>
     selector:
       matchLabels:
         app: high-demand-app
     template:
       metadata:
         labels:
           app: high-demand-app
       spec:
         nodeSelector: # <2>
           node-role.kubernetes.io/spot: ""
         containers:
           - name: nginx
             image: nginxinc/nginx-unprivileged:alpine
             ports:
               - containerPort: 80
             resources: # <3>
               requests:
                 cpu: "200m" # Requesting 200m CPU per pod
               limits:
                 cpu: "500m"
   ----
   <1> Set a high number of replicas to trigger scaling.
   <2> This `nodeSelector` ensures these pods *only* schedule on your spot nodes.
   <3> Define resource requests to allow the Cluster Autoscaler to make informed decisions.

c. *Deploy the application:*

   [source,bash]
   ----
   oc apply -f test-app-deployment.yaml -n autoscaling-test
   ----

d. *Monitor for pending pods:*
   Initially, many pods will be in a `Pending` state because there are no spot nodes available.

   [source,bash]
   ----
   oc get pods -n autoscaling-test
   ----

e. *Observe node scaling:*
   Watch the `MachineSet` and `MachineAutoscaler` for changes. The Cluster Autoscaler will detect the pending pods and instruct the `MachineAutoscaler` to scale up the `spot-worker` MachineSet.

   [source,bash]
   ----
   watch oc get machinesets -n openshift-machine-api
   ----
   You should see the `DESIRED` and `CURRENT` counts for your `spot-worker` MachineSet gradually increase up to `maxReplicas`.

   Also, monitor the nodes:
   [source,bash]
   ----
   watch oc get nodes
   ----
   New nodes with the `spot` label should appear and eventually reach the `Ready` state.

f. *Verify pods are scheduled:*
   Once new spot nodes are ready, your `high-demand-app` pods should start moving from `Pending` to `Running` on these new nodes.

   [source,bash]
   ----
   oc get pods -n autoscaling-test -o wide
   ----

.Clean Up
To scale down the cluster and clean up the resources:

a. *Scale down the application deployment:*
   This will remove the demand for the spot nodes.

   [source,bash]
   ----
   oc scale deployment/high-demand-app --replicas=0 -n autoscaling-test
   ----

b. *Observe nodes scaling down:*
   The Cluster Autoscaler will detect that the spot nodes are underutilized (or empty) and will gracefully terminate them, scaling the `MachineSet` back down to `minReplicas` (0 in our case). This might take several minutes as the autoscaler waits to ensure nodes are truly idle.

   [source,bash]
   ----
   watch oc get machinesets -n openshift-machine-api
   watch oc get nodes
   ----

c. *Delete the test application and project:*

   [source,bash]
   ----
   oc delete deployment high-demand-app -n autoscaling-test
   oc delete project autoscaling-test
   ----

d. *Delete the MachineAutoscaler:*
   If you no longer need the autoscaling for spot instances, delete the `MachineAutoscaler`.

   [source,bash]
   ----
   oc delete machineautoscaler spot-worker-autoscaler -n openshift-machine-api
   ----

e. *Delete the Spot MachineSet:*
   Finally, delete the `MachineSet` if you don't intend to use spot instances again.

   [source,bash]
   ----
   oc delete machineset aro-cluster-xxxx-spot-worker-eastus1 -n openshift-machine-api
   ----

This concludes the lab on configuring node autoscaling in Azure Red Hat OpenShift. You have successfully implemented a dynamic scaling solution for your cluster, demonstrating how to integrate Azure Spot VMs for cost-effective, elastic capacity.