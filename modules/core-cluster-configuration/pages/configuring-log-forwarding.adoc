#  Configuring log forwarding

= Configuring Log Forwarding in Azure Red Hat OpenShift

This section details how to configure log forwarding in Azure Red Hat OpenShift (ARO), enabling centralized collection and analysis of cluster logs.

== Understanding Log Forwarding in ARO

In a complex, distributed environment like Azure Red Hat OpenShift, efficient log management is crucial for monitoring, troubleshooting, auditing, and maintaining the health and security of your applications and infrastructure. Log forwarding involves collecting logs from various sources within your ARO cluster and sending them to an external, centralized logging solution for storage, analysis, and visualization.

=== Why Forward Logs?

*   *Centralized Visibility:* Aggregate logs from all pods, nodes, and OpenShift components into a single platform.
*   *Enhanced Troubleshooting:* Quickly diagnose issues by searching and correlating logs across the entire cluster.
*   *Compliance and Auditing:* Store logs securely for compliance requirements and security auditing.
*   *Performance Monitoring:* Analyze log patterns to identify performance bottlenecks and system anomalies.
*   *Long-term Storage:* Retain logs for extended periods, beyond the lifecycle of individual pods or nodes.

=== OpenShift Logging Architecture

OpenShift Container Platform (OCP), and by extension ARO, leverages the Cluster Logging Operator to manage the logging subsystem. The core components involved in log forwarding include:

*   **Cluster Logging Operator (CLO):** This operator manages the deployment and lifecycle of the logging components. It's responsible for deploying Fluentd/Fluent Bit and other logging resources.
*   **Fluentd / Fluent Bit:** These are high-performance, lightweight log processors and forwarders that run as DaemonSets on each worker node and sometimes as a Deployment for collecting audit logs. They collect logs from container `stdout`/`stderr`, node journal, and OpenShift audit logs.
*   **ClusterLogForwarder Custom Resource (CR):** This OpenShift custom resource defines the destinations for your logs (e.g., Azure Log Analytics, Splunk, Kafka, HTTP endpoints) and specifies which types of logs (application, infrastructure, audit) should be forwarded to which destination.
*   **ClusterLogging Custom Resource (CR):** This CR is used to deploy and configure the core logging stack (Fluentd/Fluent Bit). While you *can* include an internal Elasticsearch/OpenSearch for log storage, the focus for forwarding is often to external systems. For simple forwarding without internal storage, you typically define a minimal `ClusterLogging` instance.

.Log Flow in OpenShift
Logs generated by applications (containers) are written to `stdout` and `stderr`. The container runtime captures these logs, which are then collected by Fluentd/Fluent Bit agents running on each node. The Cluster Logging Operator, configured via a `ClusterLogForwarder` resource, processes these collected logs and sends them to the specified external destination.

image::aro-log-forwarding-flow.png[Log Forwarding Flow Diagram, width=800, link="https://example.com/aro-log-forwarding-flow.png"]
_Diagram: High-level overview of log forwarding in ARO, showing log sources, Fluentd/Fluent Bit, and external destinations._

=== Types of Logs

The Cluster Logging solution can forward three main types of logs:

*   **Application logs:** Logs generated by user applications running in pods. These are typically collected from `stdout` and `stderr`.
*   **Infrastructure logs:** Logs from the OpenShift platform components themselves, such as `kubelet`, `kube-proxy`, `CRI-O`, `etcd`, `controller-manager`, etc. These provide insights into the health and operation of the cluster.
*   **Audit logs:** Security-relevant chronological records of events, such as API requests to the Kubernetes API server or OpenShift OAuth server. These are crucial for security monitoring and compliance.

=== Prerequisites

Before configuring log forwarding, ensure you have:

*   An existing Azure Red Hat OpenShift (ARO) cluster.
*   `kubeadmin` credentials or an OpenShift user with `cluster-admin` privileges.
*   The `oc` CLI tool configured and authenticated to your ARO cluster.
*   An external logging solution provisioned and accessible. For this guide, we'll use an Azure Log Analytics Workspace.

== Hands-on Activity: Configuring Log Forwarding to Azure Log Analytics

In this hands-on lab, you will configure your ARO cluster to forward application, infrastructure, and audit logs to an Azure Log Analytics Workspace.

=== Step 1: Create an Azure Log Analytics Workspace

First, you need an Azure Log Analytics Workspace to receive the logs.

. Open your Azure Cloud Shell or a local terminal with Azure CLI installed.
. Create a resource group for your Log Analytics Workspace (if you don't have one).
+
[source,bash]
----
AZ_RG="aro-log-rg"
AZ_LOCATION="eastus" # Use the same location as your ARO cluster for optimal performance
az group create --name $AZ_RG --location $AZ_LOCATION
----
. Create the Log Analytics Workspace.
+
[source,bash]
----
AZ_LA_WORKSPACE_NAME="aro-logs-workspace"
az monitor log-analytics workspace create \
    --resource-group $AZ_RG \
    --workspace-name $AZ_LA_WORKSPACE_NAME \
    --location $AZ_LOCATION
----
. Retrieve the Workspace ID and Primary Shared Key. You will need these to configure the log forwarder in OpenShift.
+
[source,bash]
----
AZ_LA_WORKSPACE_ID=$(az monitor log-analytics workspace show \
    --resource-group $AZ_RG \
    --workspace-name $AZ_LA_WORKSPACE_NAME \
    --query customerId --output tsv)
echo "Log Analytics Workspace ID: $AZ_LA_WORKSPACE_ID"

AZ_LA_PRIMARY_SHARED_KEY=$(az monitor log-analytics workspace get-shared-keys \
    --resource-group $AZ_RG \
    --workspace-name $AZ_LA_WORKSPACE_NAME \
    --query primarySharedKey --output tsv)
echo "Log Analytics Primary Shared Key: $AZ_LA_PRIMARY_SHARED_KEY"
----

.Keep these values handy. You'll use them to create a Kubernetes Secret.

=== Step 2: Install the OpenShift Logging Operator

The Cluster Logging Operator manages the logging stack.

. Log in to the OpenShift Web Console as `kubeadmin` or a user with `cluster-admin` privileges.
. Navigate to `Operators` -> `OperatorHub`.
. Search for "OpenShift Logging" and select it.
. Click `Install`.
. On the "Install Operator" page:
    *   Set `Installation mode` to `All namespaces on the cluster (default)`.
    *   Set `Update channel` to the recommended stable channel (e.g., `stable-5.x`).
    *   Set `Approval strategy` to `Automatic`.
. Click `Install`.
. Wait for the operator to be installed. You can verify its status under `Operators` -> `Installed Operators`. It should show `Succeeded` in the `openshift-logging` project.

=== Step 3: Create a `ClusterLogging` Instance

A minimal `ClusterLogging` instance is required to deploy the Fluentd/Fluent Bit log collectors, even if you're not using the internal Elasticsearch.

. In the OpenShift Web Console, navigate to `Operators` -> `Installed Operators`.
. Click on the "OpenShift Logging" operator in the `openshift-logging` project.
. Go to the `Cluster Logging` tab.
. Click `Create ClusterLogging`.
. Switch to the `YAML view` and replace the content with the following minimal configuration:
+
[source,yaml]
----
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
  namespace: "openshift-logging"
spec:
  managementState: "Managed"
  logStore:
    type: "none" # We are not using an internal log store for this exercise
  visualization:
    type: "none" # We are not using internal visualization
  collection:
    logs:
      type: "fluentd" # Use fluentd as the log collector
----
. Click `Create`.

.Verification
Wait for the `log-collector-*` pods to be created and become `Running` in the `openshift-logging` namespace. You can monitor this from `Workloads` -> `Pods` or using `oc get pods -n openshift-logging`.

=== Step 4: Create a Secret for Log Analytics Credentials

The Log Analytics Workspace ID and Shared Key are sensitive. Store them in a Kubernetes Secret.

. Base64 encode your Workspace ID and Primary Shared Key.
+
[source,bash]
----
echo -n "$AZ_LA_WORKSPACE_ID" | base64
echo -n "$AZ_LA_PRIMARY_SHARED_KEY" | base64
----
. Replace the `workspaceId` and `sharedKey` values in the YAML below with your base64-encoded strings.
. Create the Secret in the `openshift-logging` namespace.
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: log-analytics-secret
  namespace: openshift-logging
stringData:
  # Replace with your actual Workspace ID
  workspaceId: "<YOUR_BASE64_ENCODED_WORKSPACE_ID>"
  # Replace with your actual Primary Shared Key
  sharedKey: "<YOUR_BASE64_ENCODED_PRIMARY_SHARED_KEY>"
----
+
[source,bash]
----
oc apply -f - <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: log-analytics-secret
  namespace: openshift-logging
stringData:
  workspaceId: "your-base64-encoded-workspace-id"
  sharedKey: "your-base64-encoded-primary-shared-key"
EOF
----
.NOTE: In a real-world scenario, you might use an external secrets management solution like Azure Key Vault integrated with OpenShift for better security practices.

=== Step 5: Create a `ClusterLogForwarder` Instance

Now, define the `ClusterLogForwarder` resource to direct logs to Azure Log Analytics.

. In the OpenShift Web Console, navigate to `Operators` -> `Installed Operators`.
. Click on the "OpenShift Logging" operator in the `openshift-logging` project.
. Go to the `Cluster Log Forwarders` tab.
. Click `Create ClusterLogForwarder`.
. Switch to the `YAML view` and replace the content with the following:
+
[source,yaml]
----
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogForwarder"
metadata:
  name: "instance"
  namespace: "openshift-logging"
spec:
  outputs:
    - name: log-analytics-output
      type: azureMonitor
      azureMonitor:
        customerId:
          secret:
            key: workspaceId
            name: log-analytics-secret
        sharedKey:
          secret:
            key: sharedKey
            name: log-analytics-secret
  pipelines:
    - name: app-logs-to-la
      inputRefs:
        - application
      outputRefs:
        - log-analytics-output
      labels:
        log_type: application
    - name: infra-logs-to-la
      inputRefs:
        - infrastructure
      outputRefs:
        - log-analytics-output
      labels:
        log_type: infrastructure
    - name: audit-logs-to-la
      inputRefs:
        - audit
      outputRefs:
        - log-analytics-output
      labels:
        log_type: audit
----
. Click `Create`.

.Explanation of the `ClusterLogForwarder`
*   The `outputs` section defines `log-analytics-output` of `type: azureMonitor`. It references the `log-analytics-secret` for `customerId` (Workspace ID) and `sharedKey`.
*   The `pipelines` section defines three pipelines:
    *   `app-logs-to-la`: Forwards `application` logs.
    *   `infra-logs-to-la`: Forwards `infrastructure` logs.
    *   `audit-logs-to-la`: Forwards `audit` logs.
*   All pipelines use `log-analytics-output` as their destination.
*   `labels` are added to distinguish log types within Log Analytics.

.Verification
After creating the `ClusterLogForwarder`, the Cluster Logging Operator will reconcile the changes. This might cause the `log-collector-*` pods to restart as new configurations are applied.

=== Step 6: Verify Log Forwarding in Azure Log Analytics

. Deploy a sample application to generate some logs.
+
[source,yaml]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  name: log-generator
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: log-generator
  template:
    metadata:
      labels:
        app: log-generator
    spec:
      containers:
      - name: log-generator
        image: busybox
        command: ["sh", "-c"]
        args:
        - while true; do
            echo "$(date) - Hello from ARO log generator!";
            sleep 5;
          done
----
+
[source,bash]
----
oc apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: log-generator
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: log-generator
  template:
    metadata:
      labels:
        app: log-generator
    spec:
      containers:
      - name: log-generator
        image: busybox
        command: ["sh", "-c"]
        args:
        - while true; do
            echo "$(date) - Hello from ARO log generator!";
            sleep 5;
          done
EOF
----
. Open the Azure Portal and navigate to your Log Analytics Workspace (`aro-logs-workspace`).
. In the workspace, click on `Logs` under the `General` section.
. Close any pop-ups and enter the following Kusto Query Language (KQL) query:
+
[source,kql]
----
ContainerLogV2
| where ClusterName == "your-aro-cluster-name" // Replace with your ARO cluster name
| where ContainerName == "log-generator"
| project TimeGenerated, LogMessage
| order by TimeGenerated desc
----
. Click `Run`. You should start seeing logs from your `log-generator` application appearing in Log Analytics.

.Additional Queries
*   To see all `application` logs forwarded:
+
[source,kql]
----
ContainerLogV2
| where labels.log_type == "application"
| limit 50
| project TimeGenerated, LogMessage
----
*   To see `infrastructure` logs:
+
[source,kql]
----
ContainerLogV2
| where labels.log_type == "infrastructure"
| limit 50
| project TimeGenerated, LogMessage
----
*   To see `audit` logs (these might appear in a different table like `KubeAudit` or `ContainerLogV2` depending on configuration and version, so start by searching `ContainerLogV2` with `labels.log_type == "audit"` or explore tables like `KubeAudit`):
+
[source,kql]
----
ContainerLogV2
| where labels.log_type == "audit"
| limit 50
| project TimeGenerated, LogMessage
----
If you don't immediately see audit logs, try querying `KubeAudit` or `AzureDiagnostics` tables if they exist and contain audit events. The exact table for audit logs can vary.

== Troubleshooting Log Forwarding

If logs are not appearing in your external destination, consider the following troubleshooting steps:

. Check `ClusterLogging` and `ClusterLogForwarder` Status
*   In the OpenShift Web Console, navigate to `Operators` -> `Installed Operators` -> `OpenShift Logging`.
*   Check the `Cluster Logging` and `Cluster Log Forwarders` tabs. Ensure both instances show a `Healthy` status and no errors in their conditions.

. Examine `log-collector` Pods
*   The `log-collector-*` pods (Fluentd/Fluent Bit) are responsible for collecting and forwarding logs. Check their status and logs.
+
[source,bash]
----
oc get pods -n openshift-logging -l logging-infra=collector
oc logs -f <log-collector-pod-name> -n openshift-logging
----
*   Look for errors related to connecting to the external destination, authentication issues, or parsing problems.

. Verify Network Connectivity
*   Ensure that the `openshift-logging` namespace, specifically the `log-collector` pods, has network egress connectivity to the Azure Log Analytics endpoint. Azure Red Hat OpenShift clusters typically have outbound internet access by default, but custom Network Policies or egress firewalls could block traffic.
*   The Azure Log Analytics endpoint is `https://<Workspace ID>.ods.opinsights.azure.com`. You can attempt a `curl` from within a `log-collector` pod if you exec into it, but this might require adding `curl` temporarily.

. Recheck Secret and Output Configuration
*   Ensure that the `log-analytics-secret` contains the correct base64-encoded Workspace ID and Shared Key.
*   Verify that the `ClusterLogForwarder` YAML correctly references the secret keys (`workspaceId` and `sharedKey`) and the secret name (`log-analytics-secret`). Typographical errors are common.

. Increase Verbosity (for advanced troubleshooting)
*   For Fluentd/Fluent Bit, you can sometimes adjust logging levels in the `ClusterLogging` CR, but this is less common for simple forwarding issues. Refer to OpenShift documentation for advanced `ClusterLogging` configuration.

. Consult OpenShift and Azure Documentation
*   Refer to the official Red Hat OpenShift documentation for Cluster Logging: link:https://docs.openshift.com/container-platform/latest/logging/cluster-logging-ossm-log-collection.html[OpenShift Logging Overview]
*   Refer to Azure Monitor documentation for Log Analytics integration: link:https://learn.microsoft.com/en-us/azure/azure-monitor/logs/data-sources-kubernetes[Collect Kubernetes logs with Azure Monitor]

This guide provides a comprehensive approach to setting up log forwarding from your ARO cluster to Azure Log Analytics, a crucial step for effective cluster management and observability.